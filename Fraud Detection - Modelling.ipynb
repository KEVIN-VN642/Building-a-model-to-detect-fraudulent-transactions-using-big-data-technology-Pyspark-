{"cells":[{"cell_type":"markdown","source":["# FRAUD DETECTION - MODELLING\n\nThis Notebook contains modelling part and it is the second of the two notebooks, so this notebook inherits analysis from the first notebook."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e0532125-9d46-40f5-94df-e6f4ccdbee3a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Importing Libraries"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"09660cae-66a9-4b11-a376-9e8eeabd09b9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pandas as pd\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\nfrom pyspark.sql import functions as f\nfrom pyspark.sql.types import FloatType\n\nfrom pyspark.ml.stat import Correlation\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler, IndexToString, StringIndexer, VectorIndexer\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.classification import RandomForestClassifier, GBTClassifier, LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\nfrom pyspark.mllib.evaluation import MulticlassMetrics\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.functions import col,sum\nfrom pyspark.ml.param import Param, Params"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"79430b7d-7dc7-4005-a516-7c8a6efb9b34","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Importing Data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2564786f-05ff-45ef-b2d2-f847735c7992","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["dataPath = \"/FileStore/tables/creditcard.csv\"\ndf = spark.read\\\n    .option(\"header\", \"true\")\\\n    .option(\"inferSchema\", \"true\")\\\n    .csv(dataPath)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3b1b7326-ce87-4f22-8cd2-f4babccb15c4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Dropping Time Features"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"20eeaa8b-b798-476c-b182-0010a205f98f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Dropping the Time column\ndf = df.drop('Time')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d602a7ee-64dd-4b4d-82e2-c18e331f2f8e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Splitting Data\nNow we split the dataset 75-25 for training and testing purposes.<br>\nOur target feature is the Class column and it has 2 unique values, 1 for fraudulant transactions and 0 for non-fraudulent transactions."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5ac94e14-8124-4ab3-8599-a48a3a449df0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df_train, df_test = df.randomSplit([0.75, 0.25], seed=123)\n\n# Caching the data\ndf_train.cache()\ndf_test.cache()\n\nprint(\"Number ot Training data: \" + str(df_train.count()))\nprint(\"Number ot Test data: \" + str(df_test.count()))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"70d0ac90-bfb8-48c6-8201-de366730ec6e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Number ot Training data: 214074\nNumber ot Test data: 70733\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Number ot Training data: 214074\nNumber ot Test data: 70733\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Data Balancing\nWe used the oversampling method to correct for the data imbalance.<br>\nThr altenative would have been to use undersampling, but given that there is a fairly small number of fraudulent transactions, undersampling would leave us with a very small dataset for the modeling, which would lead to weak models."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5a415895-c18c-4850-8c05-97d2c086f923","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["major_df_train = df_train.filter(f.col(\"Class\") == 0)\nminor_df_train = df_train.filter(f.col(\"Class\") == 1)\nratio = int(major_df_train.count()/minor_df_train.count())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"69cf0ddc-78ac-4266-ba1e-a0148546a4a9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# There are 571 non-fraudulent transactions for each fraudulent transaction\nprint(\"In the training set, for every fraudulent transaction there are {}\".format(ratio),'non-fraudulent transactions.')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3fe58650-d099-490e-a6d4-bf4528cf9e53","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"In the training set, for every fraudulent transaction there are 576 non-fraudulent transactions.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["In the training set, for every fraudulent transaction there are 576 non-fraudulent transactions.\n"]}}],"execution_count":0},{"cell_type":"code","source":["a = range(70)\n# Duplicate the minority rows\noversampled_df = minor_df_train.withColumn(\"dummy\", f.explode(f.array([f.lit(x) for x in a]))).drop('dummy')\n\n# Combine both oversampled minority rows and previous majority rows \nbalanced_df_train = major_df_train.unionAll(oversampled_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1fcbc4f2-ce78-46b1-b3f5-4ed9a6587a4d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["balanced_df_train.groupBy(\"Class\").count().withColumn(\"%\", col('count')/balanced_df_train.count()*100).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0e770c5c-a181-40f1-94a2-2dd884410b68","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----+------+------------------+\n|Class| count|                 %|\n+-----+------+------------------+\n|    0|213703|  89.1644031659803|\n|    1| 25970|10.835596834019686|\n+-----+------+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----+------+------------------+\n|Class| count|                 %|\n+-----+------+------------------+\n|    0|213703|  89.1644031659803|\n|    1| 25970|10.835596834019686|\n+-----+------+------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Vectorizing\nNow that all of our data is ready. We're going to have to put all of it into one column of a vector type for Spark MLLib. This makes it easy to embed a prediction right in a DataFrame and also makes it very clear as to what is getting passed into the model and what isn't. This also makes it easy to incrementally add new features, simply by adding to the vector."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e8fc5015-0f27-498e-a67b-8d0858f96c37","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["nonFeatureCols = [\"Class\"]\nfeatureCols = [item for item in df.columns if item not in nonFeatureCols]\nprint(featureCols)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"178df8cb-0d27-4001-b128-e4b7f0f738c1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n"]}}],"execution_count":0},{"cell_type":"code","source":["assembler = (VectorAssembler()\n  .setInputCols(featureCols)\n  .setOutputCol(\"features\"))\n\ndf_train = assembler.transform(balanced_df_train)\ndf_test = assembler.transform(df_test)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"40fe785b-5141-4c54-95a0-908a89dbc0b3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## MODELING"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8296b898-ea90-4fb8-b315-4331d0a9b4da","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Creating a Results dataframe to store results\nResults = pd.DataFrame(columns =[\"Model\",\"Recall\", \"Precision\", \"F1\", \"PR_AUC\", \"ROC_AUC\"])\nResults"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9268ff5c-c0ea-4cfd-9f19-709ad92d6ff4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n      <th>PR_AUC</th>\n      <th>ROC_AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>F1</th>\n      <th>PR_AUC</th>\n      <th>ROC_AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Logistic Regression Model\n\nUsing logistic regression to predict fraud."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bc69bda7-d24d-48cd-a3c4-9c6cd7f708d1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["logis = LogisticRegression(labelCol='Class',featuresCol='features',family='binomial')\nlogis_paramGrid = (ParamGridBuilder()\n  .addGrid(logis.maxIter, [15])\n  .addGrid(logis.threshold, [0.95, 0.8, 0.5])\n  .build())\n\nlogis_pipeline = Pipeline().setStages([logis])\n\nlogis_cv = (CrossValidator(numFolds = 5, seed = 1) \n  .setEstimator(logis_pipeline) \n  .setEstimatorParamMaps(logis_paramGrid)\n  .setEvaluator(BinaryClassificationEvaluator(metricName = \"areaUnderPR\").setLabelCol(\"Class\")))\nlogis_cv_fit = logis_cv.fit(df_train)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2e5bb458-b682-4f22-8a03-027fcd2bdb30","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Get peformance metrics\nlogis_prediction = logis_cv_fit.transform(df_test)\nlogis_conf_matrix = logis_prediction.groupBy(['Class', 'prediction']).count().toPandas().pivot(index = 'Class', columns='prediction', values='count')\n\nprint(\"Confusion Matrix: \\n\",logis_conf_matrix)\n\nlogis_precision = logis_conf_matrix[1][1]/(logis_conf_matrix[1].sum())\n\nlogis_recall = logis_conf_matrix[1][1]/(logis_conf_matrix.iloc[1].sum())\n\nlogis_f1 = 2*logis_recall*logis_precision/(logis_recall + logis_precision)\n\nlogis_ROC_AUC = BinaryClassificationEvaluator(labelCol=\"Class\", metricName = \"areaUnderROC\").evaluate(logis_prediction)\n\nlogis_PR_AUC = BinaryClassificationEvaluator(labelCol=\"Class\", metricName = \"areaUnderPR\").evaluate(logis_prediction)\n\nResults.loc[len(Results.index)] = [\"Logistic Regression\",logis_recall, logis_precision, logis_f1, logis_PR_AUC, logis_ROC_AUC]\n\nprint(Results)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"be39a483-7ebd-4cbd-a726-b1c0c78e79fe","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Confusion Matrix: \n prediction    0.0  1.0\nClass                 \n0           70560   52\n1              19  102\n                 Model    Recall  Precision        F1    PR_AUC   ROC_AUC\n0  Logistic Regression  0.842975   0.662338  0.741818  0.766738  0.976402\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Confusion Matrix: \n prediction    0.0  1.0\nClass                 \n0           70560   52\n1              19  102\n                 Model    Recall  Precision        F1    PR_AUC   ROC_AUC\n0  Logistic Regression  0.842975   0.662338  0.741818  0.766738  0.976402\n"]}}],"execution_count":0},{"cell_type":"code","source":["logis_prediction.groupBy(['Class', 'prediction']).count().toPandas().pivot(index = 'Class', columns='prediction', values='count')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7b8ad9c3-b782-4fcb-9bf0-87215f13d947","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>prediction</th>\n      <th>0.0</th>\n      <th>1.0</th>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70560</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19</td>\n      <td>102</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>prediction</th>\n      <th>0.0</th>\n      <th>1.0</th>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70560</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>19</td>\n      <td>102</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Random Forest Model\n\nUsing Random forest to predict fraud."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"70bc0793-83bc-49d7-b376-26ee25cfb479","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["CV_RF = RandomForestClassifier(labelCol = 'Class', featuresCol = 'features', seed = 4)\nrf_paramGrid = (ParamGridBuilder()\n  .addGrid(CV_RF.maxDepth, [8])\n  .addGrid(CV_RF.numTrees, [30, 60])\n  .build())\n\nrf_pipeline = Pipeline().setStages([CV_RF])\n\nrf_cv = (CrossValidator(numFolds = 5, seed = 1) \n  .setEstimator(rf_pipeline) \n  .setEstimatorParamMaps(rf_paramGrid)\n  .setEvaluator(BinaryClassificationEvaluator().setLabelCol(\"Class\")))\n\nrf_cv_fit = rf_cv.fit(df_train)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a949c7d2-9e79-4734-8bef-c6ab9eb7d078","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Get peformance metrics of random forest models\nrf_prediction = rf_cv_fit.transform(df_test)\nrf_conf_matrix = rf_prediction.groupBy(['Class', 'prediction']).count().toPandas().pivot(index = 'Class', columns='prediction', values='count')\n\nprint(\"Confusion Matrix: \\n\",rf_conf_matrix)\n\nrf_precision = rf_conf_matrix[1][1]/(rf_conf_matrix[1].sum())\n\nrf_recall = rf_conf_matrix[1][1]/(rf_conf_matrix.iloc[1].sum())\n\nrf_f1 = 2*rf_recall*rf_precision/(rf_recall + rf_precision)\n\nrf_ROC_AUC = BinaryClassificationEvaluator(labelCol=\"Class\", metricName = \"areaUnderROC\").evaluate(rf_prediction)\n\nrf_PR_AUC = BinaryClassificationEvaluator(labelCol=\"Class\", metricName = \"areaUnderPR\").evaluate(rf_prediction)\n\nResults.loc[len(Results.index)] = [\"Random Forest\",rf_recall, rf_precision, rf_f1, rf_PR_AUC, rf_ROC_AUC]\n\nprint(Results)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8eaf2869-a206-45be-b80d-aaac8b0ef8e9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Confusion Matrix: \n prediction    0.0  1.0\nClass                 \n0           70590   22\n1              21  100\n                 Model    Recall  Precision        F1    PR_AUC   ROC_AUC\n0  Logistic Regression  0.842975   0.662338  0.741818  0.766738  0.976402\n1        Random Forest  0.826446   0.819672  0.823045  0.839597  0.977960\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Confusion Matrix: \n prediction    0.0  1.0\nClass                 \n0           70590   22\n1              21  100\n                 Model    Recall  Precision        F1    PR_AUC   ROC_AUC\n0  Logistic Regression  0.842975   0.662338  0.741818  0.766738  0.976402\n1        Random Forest  0.826446   0.819672  0.823045  0.839597  0.977960\n"]}}],"execution_count":0},{"cell_type":"code","source":["rf_prediction.groupBy(['Class', 'prediction']).count().toPandas().pivot(index = 'Class', columns='prediction', values='count')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a4ad2c94-ded4-46c4-b2d1-95d48e91cee6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>prediction</th>\n      <th>0.0</th>\n      <th>1.0</th>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70590</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>prediction</th>\n      <th>0.0</th>\n      <th>1.0</th>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70590</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Gradient Boosted Tree\n\nUsing GBT to predict fraud."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b7fa17dc-41ab-4c7d-88a3-9a72d8b97cf9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["gbt = GBTClassifier(labelCol = 'Class', featuresCol = 'features', maxDepth = 8)\n\ngbt_fit = gbt.fit(df_train)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"26fc33b6-74e9-4a7f-975b-45addc9fd7ce","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Get peformance metrics of GBT model\ngbt_prediction = gbt_fit.transform(df_test)\ngbt_conf_matrix = gbt_prediction.groupBy(['Class', 'prediction']).count().toPandas().pivot(index = 'Class', columns='prediction', values='count')\n\nprint(\"Confusion Matrix: \\n\",gbt_conf_matrix)\n\ngbt_precision = gbt_conf_matrix[1][1]/(gbt_conf_matrix[1].sum())\n\ngbt_recall = gbt_conf_matrix[1][1]/(gbt_conf_matrix.iloc[1].sum())\n\ngbt_f1 = 2*gbt_recall*gbt_precision/(gbt_recall + gbt_precision)\n\ngbt_ROC_AUC = BinaryClassificationEvaluator(labelCol=\"Class\", metricName = \"areaUnderROC\").evaluate(gbt_prediction)\n\ngbt_PR_AUC = BinaryClassificationEvaluator(labelCol=\"Class\", metricName = \"areaUnderPR\").evaluate(gbt_prediction)\n\nResults.loc[len(Results.index)] = [\"Gradient Boosted Tree\",gbt_recall, gbt_precision, gbt_f1, gbt_PR_AUC, gbt_ROC_AUC]\n\nprint(Results)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5a718f7b-1bc7-45f2-bb7d-37fd5799b154","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Confusion Matrix: \n prediction    0.0  1.0\nClass                 \n0           70565   47\n1              29   92\n                   Model    Recall  Precision        F1    PR_AUC   ROC_AUC\n0    Logistic Regression  0.842975   0.662338  0.741818  0.766738  0.976402\n1          Random Forest  0.826446   0.819672  0.823045  0.839597  0.977960\n2  Gradient Boosted Tree  0.760331   0.661871  0.707692  0.770578  0.942938\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Confusion Matrix: \n prediction    0.0  1.0\nClass                 \n0           70565   47\n1              29   92\n                   Model    Recall  Precision        F1    PR_AUC   ROC_AUC\n0    Logistic Regression  0.842975   0.662338  0.741818  0.766738  0.976402\n1          Random Forest  0.826446   0.819672  0.823045  0.839597  0.977960\n2  Gradient Boosted Tree  0.760331   0.661871  0.707692  0.770578  0.942938\n"]}}],"execution_count":0},{"cell_type":"code","source":["gbt_prediction.groupBy(['Class', 'prediction']).count().toPandas().pivot(index = 'Class', columns='prediction', values='count')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"40c3ba44-d4c2-46de-add1-385bdbc91efc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>prediction</th>\n      <th>0.0</th>\n      <th>1.0</th>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70565</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29</td>\n      <td>92</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>prediction</th>\n      <th>0.0</th>\n      <th>1.0</th>\n    </tr>\n    <tr>\n      <th>Class</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>70565</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29</td>\n      <td>92</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# RESULTS AND CONCLUSIONS"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9e13bd58-465f-4428-b68a-b614cefa684a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["The below table summarizes the performance of the three models on the test set:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e9b45c49-a0e2-49c9-b3f3-3d9c75e29739","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["display(Results)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d5d74a1f-55b6-4d86-b2c7-b2330f2fd7cf","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Logistic Regression",0.8429752066115702,0.6623376623376623,0.7418181818181817,0.7667384417121104,0.9764020045758159],["Random Forest",0.8264462809917356,0.819672131147541,0.823045267489712,0.8395974902556095,0.9779601060480436],["Gradient Boosted Tree",0.7603305785123967,0.6618705035971223,0.7076923076923077,0.7705783729055073,0.9429379058086257]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Model","type":"\"string\"","metadata":"{}"},{"name":"Recall","type":"\"double\"","metadata":"{}"},{"name":"Precision","type":"\"double\"","metadata":"{}"},{"name":"F1","type":"\"double\"","metadata":"{}"},{"name":"PR_AUC","type":"\"double\"","metadata":"{}"},{"name":"ROC_AUC","type":"\"double\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Model</th><th>Recall</th><th>Precision</th><th>F1</th><th>PR_AUC</th><th>ROC_AUC</th></tr></thead><tbody><tr><td>Logistic Regression</td><td>0.8429752066115702</td><td>0.6623376623376623</td><td>0.7418181818181817</td><td>0.7667384417121104</td><td>0.9764020045758159</td></tr><tr><td>Random Forest</td><td>0.8264462809917356</td><td>0.819672131147541</td><td>0.823045267489712</td><td>0.8395974902556095</td><td>0.9779601060480436</td></tr><tr><td>Gradient Boosted Tree</td><td>0.7603305785123967</td><td>0.6618705035971223</td><td>0.7076923076923077</td><td>0.7705783729055073</td><td>0.9429379058086257</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The random forest model has the highest performance in terms of Precision, F1 score, PR_AUC and ROC_AUC. It also has comparable recall with other models then it is the best model. Improving recall for fraud detection means that we are improving the detection of fraudulent transactions, which is an important metric to measure our models' predictive strength."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4866bf5b-f9a6-4cb2-b5ae-a5e4d6216755","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Fraud Detection - Modelling","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":489962228684301}},"nbformat":4,"nbformat_minor":0}
